{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "#import pickle5 as pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = '/Users/timrudge/cellmodeller/data/param_scan_psi_hd_10x/'\n",
    "file_path = '../../../cellmodeller/data/killifish/Sims 11-05_long'\n",
    "\n",
    "# Location of the data we want to analyse, assume all folders are results\n",
    "folders = os.listdir(file_path)\n",
    "folders.sort()\n",
    "\n",
    "df = pd.DataFrame(columns=['Wc', 'psi', 'D', 'density', 'sim', 'time', 'max_size', 'mean_size', 'number'])\n",
    "df_dist = pd.DataFrame(columns=['Wc', 'psi', 'D', 'density', 'time', 'size'])\n",
    "\n",
    "## Add sim index\n",
    "prev_pars = {}\n",
    "i = 0\n",
    "first = True\n",
    "################\n",
    "\n",
    "steps = 10000\n",
    "for folder in folders:\n",
    "    fname = os.path.join(file_path, folder, 'step-%05d.pickle')\n",
    "    \n",
    "    ## NEW SIMS VERSION:\n",
    "    # Extract parameters from folder name\n",
    "    parts = fname.split('__')\n",
    "    Wc = float(parts[1].replace('_', '.'))\n",
    "    psi = float(parts[3].replace('_', '.'))\n",
    "    D = float(parts[5].replace('_', '.'))\n",
    "    N = int(parts[8].split('_')[0])\n",
    "    sphere_rad = float(parts[10].replace('_', '.'))\n",
    "    density = N / (4 * sphere_rad**2)\n",
    "    forg = parts[12].split('-')[0] # later check if necessary to add to the df\n",
    "    \n",
    "    \n",
    "    ### Add sim index to df\n",
    "    prev_pars_aux = {'Wc':Wc,'psi':psi,'D':D,'density':density}\n",
    "    if first:\n",
    "        prev_pars = prev_pars_aux\n",
    "        first = False\n",
    "    if prev_pars != prev_pars_aux:\n",
    "        #print(\"not eq\")\n",
    "        i=0\n",
    "        prev_pars = prev_pars_aux\n",
    "    elif prev_pars == prev_pars_aux:\n",
    "        #print(\"eq\")\n",
    "        prev_pars = prev_pars_aux\n",
    "        i+=1\n",
    "    #print(i)\n",
    "    \n",
    "    \n",
    "    # Look at the first 1000 time steps of this simulation\n",
    "    for t in range(0,steps,10):\n",
    "        # Get the cell states\n",
    "        data = pickle.load(open(fname%t, 'rb'))\n",
    "        cs = data['cellStates']\n",
    "        # Construct a graph with cells as nodes and cell-cell contacts as edges\n",
    "        G = nx.Graph()\n",
    "        for id,cell in cs.items():\n",
    "            for n in cell.neighbours:\n",
    "                G.add_edge(id, n)\n",
    "        # Get the sizes of the connected components = clusters\n",
    "        sizes = [len(c) for c in nx.connected_components(G)]\n",
    "        if len(sizes)>0:\n",
    "            # Dominant cluster size\n",
    "            max_size = np.max(sizes)\n",
    "            mean_size = np.mean(sizes)\n",
    "            # Count the number of clusters, including single cells\n",
    "            number = nx.number_connected_components(G) + N - np.sum(sizes)\n",
    "            row = {\n",
    "                'Wc': Wc, \n",
    "                'psi':psi,\n",
    "                'D': D,\n",
    "                'density':density,\n",
    "                'sim': i,\n",
    "                'time':t,                \n",
    "                'max_size':max_size, \n",
    "                'mean_size':mean_size, \n",
    "                'number':number,\n",
    "            }\n",
    "            df = df.append(row, ignore_index=True)\n",
    "            \n",
    "            ## Distribution dataframe\n",
    "            #rows = pd.DataFrame()\n",
    "            #rows['size'] = sizes\n",
    "            #rows['Wc'], rows['psi'], rows['D'], rows['time'], rows['density'] = Wc, psi, D, t, density\n",
    "            #df_dist = df_dist.append(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('df_sims_11-05_long.JSON')\n",
    "#df_dist.reset_index(inplace=True)\n",
    "#df_dist.to_json('df_dist_sims_10-21_2.JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('df_sims_11-05_long.JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters that form one cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_param_comb = df[(df.density==0.2)&(df.number==1)].groupby(['Wc', 'psi', 'D', 'density']).size().reset_index().rename(columns={0:'Count'})\n",
    "df_param_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id, row in df_param_comb.iterrows():\n",
    "    df_plot = df[(df.Wc==row['Wc'])&\n",
    "             (df.psi==row['psi'])&\n",
    "             (df.D==row['D'])&\n",
    "             (df.density==row['density'])]\n",
    "    \n",
    "    df_gg = df_plot.groupby('sim')\n",
    "    leg = f\"Wc={row['Wc']}, psi={row['psi']}, D={row['D']}, density={row['density']}\"\n",
    "    for sim, df_sim in df_gg:\n",
    "        plt.plot(df_sim['time'], df_sim['number'], '.')\n",
    "    plt.title(leg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_param_comb = df[(df.density==0.2)&(df.number==1)].groupby(['Wc', 'psi', 'D', 'density', 'sim', 'number']).size().reset_index().rename(columns={0:'Count'})\n",
    "df_param_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slopes computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('df_sims_10-21_index.JSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = df.density.unique()\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "for d in ds:\n",
    "    df_param_comb = df[df.density==d].groupby(['Wc', 'psi', 'D', 'density']).size().reset_index().rename(columns={0:'Count'})\n",
    "    for id, row in df_param_comb.iterrows():\n",
    "        df_selected = df[(df.Wc==row['Wc'])&\n",
    "                     (df.psi==row['psi'])&\n",
    "                     (df.D==row['D'])&\n",
    "                     (df.density==row['density'])]\n",
    "\n",
    "        df_gg = df_selected.groupby('sim')\n",
    "        leg = []\n",
    "        slopes_total = []\n",
    "        interceptions_total = []\n",
    "        \n",
    "        for sim, df_sim in df_gg:\n",
    "            x_0 = df_sim['time']\n",
    "            x = np.delete(np.array(df_sim['time']), 0, axis=0)\n",
    "            y = np.delete(np.array(df_sim['number']), 0, axis=0)\n",
    "            A, B = np.polyfit(np.log(x), np.log(y), 1)\n",
    "            \n",
    "            slopes_total.append(A)\n",
    "            interceptions_total.append(B)\n",
    "        \n",
    "        try:\n",
    "            df_990 = df_selected[df_selected.time==990]\n",
    "            df_990['slope'] = slopes_total\n",
    "            df_final = pd.concat([df_final, df_990], ignore_index=True)\n",
    "        except:\n",
    "            df_990 = df_selected[df_selected.time==980]\n",
    "            df_990['slope'] = slopes_total\n",
    "            df_final = pd.concat([df_final, df_990], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('df_all_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('df_all_clusters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 8, 8\n",
    "for sr, gg_sr in df_final.groupby('D'):\n",
    "    for density, gg_density in gg_sr.groupby('density'):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        tc = ax.tricontourf(gg_density['Wc'], gg_density['psi'], gg_density['slope'],  cmap=\"jet\")\n",
    "\n",
    "        cbar = fig.colorbar(tc, ax=ax)\n",
    "        cbar.set_label(\"Slope (power law)\")\n",
    "\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Dr = {sr}; Density = {round(density, 2)}\")\n",
    "        ax.set_xlabel('Wc')\n",
    "        ax.set_ylabel('Psi')\n",
    "        fig.savefig(f\"heatmap_slope__Dr__{sr}__dens__{round(density, 2)}.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NÂ° of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sr, gg_sr in df_final[df_final['time']==990].groupby('D'):\n",
    "    for density, gg_density in gg_sr.groupby('density'):\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "        tc = ax.tricontourf(gg_density['Wc'], gg_density['psi'], gg_density['number'],  cmap=\"jet\")\n",
    "\n",
    "        cbar = fig.colorbar(tc, ax=ax)\n",
    "        cbar.set_label(\"NÂ° of Clusters\")\n",
    "\n",
    "        ax.set_aspect(\"equal\")\n",
    "        ax.set_title(f\"Dr = {sr}; Density = {round(density, 2)}\")\n",
    "        ax.set_xlabel('Wc')\n",
    "        ax.set_ylabel('Psi')\n",
    "        fig.savefig(f\"heatmap_number__Dr__{sr}__dens__{round(density, 2)}.png\", dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('df_all_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 8, 8\n",
    "\n",
    "dr_gg = df_final.groupby('D')\n",
    "vals = {'number':'NÂ° of clusters', 'slope': 'Power law'}\n",
    "for val in ['number', 'slope']:\n",
    "    for dr, dr_df in dr_gg:\n",
    "        ds_gg = dr_df.groupby('density')\n",
    "        for ds, ds_df in ds_gg:\n",
    "            df_heatmap = ds_df.pivot_table(values=val,\n",
    "                                    index='psi',\n",
    "                                    columns='Wc', aggfunc=np.mean)\n",
    "            df_heatmap = df_heatmap.sort_index(axis=0, ascending=False)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            if val == 'number':\n",
    "                im = ax.imshow(df_heatmap,vmin=1, vmax=500)\n",
    "            else:\n",
    "                im = ax.imshow(df_heatmap,vmin=-1.05, vmax=0.15)\n",
    "                \n",
    "            # We want to show all ticks...\n",
    "            ax.set_xticks(np.arange(len(df_heatmap.columns)))\n",
    "            ax.set_yticks(np.arange(len(df_heatmap.index)))\n",
    "            # ... and label them with the respective list entries\n",
    "            ax.set_xticklabels(df_heatmap.columns, fontsize=16)\n",
    "            ax.set_yticklabels(df_heatmap.index, fontsize=18)\n",
    "            # Set axis titles\n",
    "            ax.set_xlabel(\"Cell adhesion\", fontsize=20)\n",
    "            ax.set_ylabel(\"CIL\", fontsize=20)\n",
    "            \n",
    "            # Loop over NÂ° of cluster data to annotate when < 1.5\n",
    "            #if val=='number':\n",
    "            \n",
    "            for i in range(len(df_heatmap.index)):\n",
    "                for j in range(len(df_heatmap.columns)):\n",
    "                    if val=='number':\n",
    "                        if df_heatmap.iloc[i,j] < 1.5:\n",
    "                            text = ax.text(j, i, df_heatmap.iloc[i,j],\n",
    "                                           ha=\"center\", va=\"center\", color=\"w\", fontsize=16)\n",
    "                    elif val=='slope':\n",
    "                        if df_heatmap.iloc[i,j] <= -2/3:\n",
    "                            text = ax.text(j, i, round(df_heatmap.iloc[i,j],2),\n",
    "                                           ha=\"center\", va=\"center\", color=\"w\", fontsize=16)\n",
    "            \n",
    "            # colorbar set up\n",
    "            cb = plt.colorbar(im,fraction=0.046, pad=0.04)\n",
    "            cb.ax.tick_params(labelsize=18)\n",
    "            cb.set_label(vals[val],size=20)\n",
    "            \n",
    "            ax.set_title(f\"Dr={dr}, density={round(ds, 2)}\", fontsize=20)\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(f\"heatmap_{val}__Dr__{dr}__dens__{round(ds, 2)}.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8x8 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moving folders to Videos/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('df_all_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../../cellmodeller/data/killifish/Sims 10-21'\n",
    "\n",
    "# Location of the data we want to analyse, assume all folders are results\n",
    "folders = os.listdir(file_path)\n",
    "folders.sort()\n",
    "\n",
    "wcs = [i.replace('.','_').split('_')[0] if int(i.replace('.','_').split('_')[1])==0 \\\n",
    "                                         else i.replace('.','_') \\\n",
    "                                         for i in map(str, df_final.Wc.unique())]\n",
    "psis = [i.replace('.','_').split('_')[0] if int(i.replace('.','_').split('_')[1])==0 \\\n",
    "                                         else i.replace('.','_') \\\n",
    "                                         for i in map(str, df_final.psi.unique())]\n",
    "\n",
    "dens = 100\n",
    "i = 0\n",
    "for wc in wcs:\n",
    "    for psi in psis:\n",
    "        name = f\"Wc__{wc}__psi__{psi}__D__1__ftax__0__500__cells_sphere__{dens}__\"\n",
    "        fold_arr = np.array(folders)\n",
    "        idx = np.flatnonzero(np.core.defchararray.find(fold_arr,name)!=-1)[0]\n",
    "        folder = fold_arr[idx]\n",
    "        #print(folder)\n",
    "        start = time.time()\n",
    "        #print(f\"{file_path}\"+\"/\"+folder+\"/\")\n",
    "        shutil.move(f\"{file_path}\"+\"/\"+folder+\"/\", \"Videos/All/\")\n",
    "        end = time.time()\n",
    "        #print(end-start)\n",
    "        \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Videos/All/\"\n",
    "for folder in os.listdir(path):\n",
    "    parts = folder.split('__')\n",
    "    Wc = parts[1]\n",
    "    psi = parts[3]\n",
    "    D = parts[5]\n",
    "    N = int(parts[8].split('_')[0])\n",
    "    sphere_rad = float(parts[10].replace('_', '.'))\n",
    "    density = round(N / (4 * sphere_rad**2),2)\n",
    "    density = str(density).replace('.', '_')\n",
    "    try:\n",
    "        file = os.path.join(path,folder,\"step-00990.png\")\n",
    "        shutil.copyfile(file, f\"Videos/'Wc__{Wc}__psi__{psi}__D__{D}__dens__{density}.png\")\n",
    "    except:\n",
    "        file = os.path.join(path,folder,\"step-00980.png\")\n",
    "        shutil.copyfile(file, f\"Videos/'Wc__{Wc}__psi__{psi}__D__{D}__dens__{density}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr = 0.1\n",
    "D = 0.1\n",
    "plt.rcParams['figure.figsize'] = 30,16\n",
    "fig,axs = plt.subplots(4,5)\n",
    "\n",
    "i = 0\n",
    "for sr, gg_sr in df[df.D==D].groupby('density'):\n",
    "    for psi, gg_psi in gg_sr.groupby('psi'):\n",
    "        legend = []\n",
    "        for Wc, gg_Wc in gg_psi.groupby('Wc'):\n",
    "            mean = gg_Wc.sort_values('time').groupby('time').mean()\n",
    "            mean.plot(y='mean_size', ax=axs[i // 5][i % 5], loglog=True, style='.-')\n",
    "            legend.append(r'$\\psi=%0.2g$, $\\phi=%0.2g$, Wc=%0.2g'%(psi,sr, Wc))\n",
    "            #print(f\"D: {D}, sr: {sr}, psi: {psi}, \")\n",
    "        axs[i // 5][i % 5].legend(legend)\n",
    "        log_min = np.log10(mean['mean_size'].min())\n",
    "        axs[i // 5][i % 5].plot([1e1,1e3], [10**log_min, 10**(log_min+2/3)], 'k--')\n",
    "        axs[i // 5][i % 5].set_ylim([0,500])\n",
    "        i+=1\n",
    "\n",
    "plt.suptitle(f\"Mean cluster size, Dr = {D}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr = 0.1\n",
    "D = 0.1\n",
    "plt.rcParams['figure.figsize'] = 30,16\n",
    "fig,axs = plt.subplots(4,5)\n",
    "\n",
    "i = 0\n",
    "for sr, gg_sr in df[df.D==D].groupby('density'):\n",
    "    for psi, gg_psi in gg_sr.groupby('psi'):\n",
    "        legend = []\n",
    "        for Wc, gg_Wc in gg_psi.groupby('Wc'):\n",
    "            mean = gg_Wc.sort_values('time').groupby('time').mean()\n",
    "            mean.plot(y='max_size', ax=axs[i // 5][i % 5], loglog=True, style='.-')\n",
    "            legend.append(r'$\\psi=%0.2g$, $\\phi=%0.2g$, Wc=%0.2g'%(psi,sr, Wc))\n",
    "            #print(f\"D: {D}, sr: {sr}, psi: {psi}, \")\n",
    "        axs[i // 5][i % 5].legend(legend)\n",
    "        log_min = np.log10(mean['mean_size'].min())\n",
    "        axs[i // 5][i % 5].plot([1e1,1e3], [10**log_min, 10**(log_min+2/3)], 'k--')\n",
    "        axs[i // 5][i % 5].set_ylim([0,500])\n",
    "        i+=1\n",
    "\n",
    "plt.suptitle(f\"Max cluster size, Dr = {D}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = df_ld_dist[(df_ld_dist.time==990) * (df_ld_dist.Wc==1) * (df_ld_dist.psi==1) * (df_ld_dist.D==0.1) * (df_ld_dist.density==0.1)]\n",
    "plt.hist(gg['size'], bins=20, log=True, alpha=0.5)\n",
    "gg = df_ld_dist[(df_ld_dist.time==990) * (df_ld_dist.Wc==1) * (df_ld_dist.psi==0)]\n",
    "plt.hist(gg['size'], bins=20, log=True, alpha=0.5)\n",
    "plt.legend(['$\\psi=1$', '$\\psi=0$'])\n",
    "\n",
    "plt.figure()\n",
    "gg = df_md_dist[(df_md_dist.time==990) * (df_md_dist.Wc==1) * (df_md_dist.psi==1)]\n",
    "plt.hist(gg['size'], bins=20, log=True, alpha=0.5)\n",
    "gg = df_md_dist[(df_md_dist.time==990) * (df_md_dist.Wc==1) * (df_md_dist.psi==0)]\n",
    "plt.hist(gg['size'], bins=20, log=True, alpha=0.5)\n",
    "plt.legend(['$\\psi=1$', '$\\psi=0$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.time==990][df.psi==1].sort_values('Wc').plot(x='Wc', y='number', style='-')\n",
    "df[df.time==990][df.psi==1].sort_values('Wc').plot(x='Wc', y='max_size', style='-')\n",
    "df[df.time==990][df.psi==1].sort_values('Wc').plot(x='Wc', y='mean_size', style='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfend = df[df.time==990]\n",
    "c1,bins1 = pd.cut(dfend.Wc, bins=10, retbins=True)\n",
    "c2,bins2 = pd.cut(dfend.psi, bins=10, retbins=True) \n",
    "hm_number = dfend.groupby([c1, c2]).number.mean().unstack()\n",
    "hm_max_size = dfend.groupby([c1, c2]).max_size.mean().unstack()\n",
    "hm_mean_size = dfend.groupby([c1, c2]).mean_size.mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,1, figsize=(5,7))\n",
    "df_Wc1 = df[df.Wc==1]\n",
    "grouped = df_Wc1.groupby('psi')\n",
    "for psi,g in grouped:\n",
    "    mean = g.sort_values('time').groupby('time').mean()\n",
    "    mean.plot(y='number', ax=axs[0], loglog=True, style='-.')\n",
    "    mean.plot(y='mean_size', ax=axs[1], loglog=True, style='-.')\n",
    "legend = ['$\\psi=%0.2g$'%psi for psi,g in grouped]\n",
    "axs[0].legend([])\n",
    "axs[1].legend(legend, loc=(1.1,0))\n",
    "axs[0].plot([1e1,1e3], [10**1.5, 10**(1.5-2/3)], 'k--')\n",
    "axs[0].set_ylim([1e0,1e2])\n",
    "axs[1].plot([1e1,1e3], [1e2, 10**(2+2/3)], 'k--')\n",
    "axs[1].set_ylim([10**1.75,1e3])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
